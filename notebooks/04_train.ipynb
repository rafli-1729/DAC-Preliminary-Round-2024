{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name='xgb', random_state=42):\n",
    "    \"\"\"\n",
    "    Mengembalikan object model yang sudah dikonfigurasi parameternya.\n",
    "    \"\"\"\n",
    "    # --- LightGBM Config ---\n",
    "    lgbm_params = {\n",
    "        'n_estimators': 5000,\n",
    "        'learning_rate': 0.0325,\n",
    "        'num_leaves': 50,\n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.65,\n",
    "        'colsample_bytree': 0.85,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'random_state': random_state,\n",
    "        'n_jobs': 1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # --- XGBoost Config ---\n",
    "    xgb_params = {\n",
    "        'n_estimators': 2600,\n",
    "        'learning_rate': 0.029244,\n",
    "        'max_depth': 8,\n",
    "        'min_child_weight': 6,\n",
    "        'subsample': 0.6568,\n",
    "        'colsample_bytree': 0.8655,\n",
    "        'reg_alpha': 0.00458,\n",
    "        'reg_lambda': 7.83e-05,\n",
    "        'n_jobs': 1,\n",
    "        'random_state': random_state,\n",
    "    }\n",
    "\n",
    "    if model_name == 'lgbm':\n",
    "        return LGBMRegressor(**lgbm_params)\n",
    "    elif model_name == 'xgb':\n",
    "        return XGBRegressor(**xgb_params)\n",
    "    else:\n",
    "        raise ValueError(\"Model not supported. Choose 'xgb' or 'lgbm'\")\n",
    "\n",
    "# Setup Data & Features\n",
    "num_cols, ord_cols, cyc_cols, sel_features = get_feature_groups(\n",
    "    train_df, TARGET, solar_lunar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4216be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    model_name, X, y, preprocessor,\n",
    "    n_splits=5, seed=42, use_sqrt_target=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Fungsi eksekusi utama: Build Pipeline -> CV -> Print Result\n",
    "    \"\"\"\n",
    "    print('='*60)\n",
    "    print(f\"üöÄ TRAINING STARTED: {model_name.upper()}\")\n",
    "    print('='*60)\n",
    "\n",
    "    # 1. Ambil Model\n",
    "    model = get_model(model_name, seed)\n",
    "\n",
    "    # 2. Bungkus Model (Opsional: TransformedTargetRegressor untuk RMSE lebih stabil)\n",
    "    if use_sqrt_target:\n",
    "        # Kalau mau pakai teknik akar kuadrat target (Pipeline_sqrt)\n",
    "        regressor = TransformedTargetRegressor(\n",
    "            regressor=model,\n",
    "            func=np.sqrt,\n",
    "            inverse_func=np.square\n",
    "        )\n",
    "    else:\n",
    "        regressor = model\n",
    "\n",
    "    # 3. Buat Pipeline Akhir\n",
    "    final_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', regressor)\n",
    "    ])\n",
    "\n",
    "    # 4. Cross Validation\n",
    "    print(f\"Running {n_splits}-Fold CV...\")\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    results = cross_validate(\n",
    "        final_pipeline, X, y,\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "\n",
    "    # 5. Reporting\n",
    "    scores = -results['test_score'] # Convert negative RMSE to positive\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    for i, score in enumerate(scores):\n",
    "        print(f\"  Fold {i+1} MSE: {score:.6f}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"üèÜ {model_name.upper()} AVG MSE: {scores.mean():.6f} (+/- {scores.std():.6f})\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    return final_pipeline, scores.mean()\n",
    "\n",
    "X = train_df[sel_features]\n",
    "y = train_df[TARGET]\n",
    "\n",
    "# Build Preprocessor\n",
    "preprocessor = build_preprocessor(num_cols, ord_cols, cyc_cols)\n",
    "\n",
    "wrapper = True\n",
    "pipeline_xgb, score_xgb = train_and_evaluate(\n",
    "    'xgb', X, y, preprocessor, N_SPLITS, SEED, use_sqrt_target=wrapper)\n",
    "\n",
    "pipeline_lgbm, score_lgbm = train_and_evaluate(\n",
    "    'lgbm', X, y, preprocessor, N_SPLITS, SEED, use_sqrt_target=wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance_final(pipeline, ord_cols, cyc_cols, num_cols, top_n=25):\n",
    "    # --- 1. BUKA BUNGKUS MODEL (UNWRAPPER) ---\n",
    "    # Ambil step 'model' dari pipeline\n",
    "    wrapper = pipeline.named_steps['model']\n",
    "\n",
    "    # Cek apakah dia TransformedTargetRegressor?\n",
    "    if hasattr(wrapper, 'regressor_'):\n",
    "        print(\"üì¶ Terdeteksi TransformedTargetRegressor. Mengambil inner model...\")\n",
    "        actual_model = wrapper.regressor_\n",
    "    else:\n",
    "        print(\"‚úÖ Model tidak dibungkus (Standard).\")\n",
    "        actual_model = wrapper\n",
    "\n",
    "    # --- 2. AMBIL NILAI IMPORTANCE ---\n",
    "    if hasattr(actual_model, 'feature_importances_'):\n",
    "        # Sklearn standard / XGBoost Scikit-Learn API\n",
    "        importances = actual_model.feature_importances_\n",
    "    elif hasattr(actual_model, 'booster_'):\n",
    "        # LightGBM Native API\n",
    "        importances = actual_model.booster_.feature_importance(importance_type='gain')\n",
    "    else:\n",
    "        print(\"‚ùå Error: Model tidak memiliki atribut feature_importances_\")\n",
    "        return\n",
    "\n",
    "    # --- 3. SUSUN NAMA FITUR (SESUAI URUTAN PREPROCESSOR) ---\n",
    "    # Logika: Ordinal -> Cyclical (di-expand jadi sin/cos) -> Numerical\n",
    "\n",
    "    # Expand Cyclical (karena pipeline cyclical memecah 1 kolom jadi 2)\n",
    "    expanded_cyc_feat = []\n",
    "    for feat in cyc_cols:\n",
    "        expanded_cyc_feat.append(f\"{feat}_sin\")\n",
    "        expanded_cyc_feat.append(f\"{feat}_cos\")\n",
    "\n",
    "    # Gabungkan list nama\n",
    "    final_names = list(ord_cols) + expanded_cyc_feat + list(num_cols)\n",
    "\n",
    "    # --- 4. VALIDASI & PLOTTING ---\n",
    "    print(f\"üìä Model Features: {len(importances)}\")\n",
    "    print(f\"üìù Feature Names : {len(final_names)}\")\n",
    "\n",
    "    if len(final_names) != len(importances):\n",
    "        print(\"‚ö†Ô∏è Warning: Jumlah fitur tidak cocok! Menggunakan nama dummy.\")\n",
    "        final_names = [f\"Feature_{i}\" for i in range(len(importances))]\n",
    "    else:\n",
    "        print(\"‚úÖ MATCH! Nama fitur sinkron.\")\n",
    "\n",
    "    # Buat DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': final_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "\n",
    "    # Sort & Plot\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False).head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
    "    plt.title(f'Top {top_n} Feature Importance (Wrapper Supported)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è≥ Training ulang model pada seluruh dataset...\")\n",
    "pipeline_xgb.fit(X, y)\n",
    "print(\"‚úÖ Model selesai dilatih!\")\n",
    "\n",
    "# 2. BARU PLOT FEATURE IMPORTANCE\n",
    "plot_importance_final(\n",
    "    pipeline_xgb,\n",
    "    ord_cols,\n",
    "    cyc_cols,\n",
    "    num_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75216c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è≥ Training ulang model pada seluruh dataset...\")\n",
    "pipeline_lgbm.fit(X, y)\n",
    "print(\"‚úÖ Model selesai dilatih!\")\n",
    "\n",
    "\n",
    "plot_importance_final(\n",
    "    pipeline_lgbm,\n",
    "    ord_cols,\n",
    "    cyc_cols,\n",
    "    num_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. PREDIKSI KE DATA TEST ---\n",
    "print(\"\\nüîÆ Predicting Test Data...\")\n",
    "# Pastikan pakai data test yang sudah di-feature engineering\n",
    "X_test = test_df\n",
    "\n",
    "pred_xgb = pipeline_xgb.predict(X_test)\n",
    "pred_lgbm = pipeline_lgbm.predict(X_test)\n",
    "\n",
    "# --- 4. BLENDING (Weighted Average) ---\n",
    "# Kasih bobot 70% XGBoost (karena skornya udah dewa) + 30% LightGBM (buat jaga-jaga)\n",
    "print(\"‚öñÔ∏è  Blending: 50% XGB + 50% LGBM\")\n",
    "final_pred = (0.45 * pred_xgb) + (0.55 * pred_lgbm)\n",
    "\n",
    "# Safety: Gak boleh negatif\n",
    "final_pred = np.maximum(final_pred, 0)\n",
    "\n",
    "# --- 5. MASKING MALAM HARI (Natural Sunrise/Sunset) ---\n",
    "print(\"üåë Applying Night Masking...\")\n",
    "\n",
    "# Ambil jam sunrise/sunset dari data test\n",
    "# Copy dulu biar gak ngerusak data asli\n",
    "temp_test = test_df.copy()\n",
    "temp_test['Timestamp'] = pd.to_datetime(temp_test['Timestamp'])\n",
    "\n",
    "# Convert string jam ke object time\n",
    "sunrise_dt = pd.to_datetime(temp_test['sunrise'], format='%I:%M %p').dt.time\n",
    "sunset_dt = pd.to_datetime(temp_test['sunset'], format='%I:%M %p').dt.time\n",
    "current_time = temp_test['Timestamp'].dt.time\n",
    "\n",
    "# Logika: Kalau jam skrg < sunrise ATAU jam skrg > sunset -> NOL\n",
    "is_night = [\n",
    "    (curr < rise) or (curr > set_)\n",
    "    for curr, rise, set_ in zip(current_time, sunrise_dt, sunset_dt)\n",
    "]\n",
    "\n",
    "# Eksekusi masking\n",
    "# final_pred[is_night] = 0\n",
    "\n",
    "# --- 6. SAVE SUBMISSION ---\n",
    "submission = pd.read_csv(SAMPLE_SUBMISSION)\n",
    "submission['% Baseline'] = final_pred\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nFile saved in submission.csv\")\n",
    "display(submission.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
