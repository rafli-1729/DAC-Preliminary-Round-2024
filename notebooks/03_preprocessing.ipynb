{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a9711e",
   "metadata": {},
   "source": [
    "# üè≠ **Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9953a",
   "metadata": {},
   "source": [
    "# üìö **Library and Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library and configuration ready!\n"
     ]
    }
   ],
   "source": [
    "# System & Environment Configuration\n",
    "import sys\n",
    "import importlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Ignore warning\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "# Core Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Source helper\n",
    "import src.preprocessing as preprocessing\n",
    "\n",
    "# Reload shortcut\n",
    "def r(module=preprocessing):\n",
    "    importlib.reload(module)\n",
    "\n",
    "r()\n",
    "\n",
    "# Train and Test Processed\n",
    "PROCESSED_ROOT = Path('../data/processed/')\n",
    "\n",
    "TRAIN_PATH_PROCESSED = PROCESSED_ROOT/'train.csv'\n",
    "TEST_PATH_PROCESSED = PROCESSED_ROOT/'test.csv'\n",
    "\n",
    "TRAIN_PATH_ENGINEERED = PROCESSED_ROOT/'train_engineered.csv'\n",
    "TEST_PATH_ENGINEERED = PROCESSED_ROOT/'test_engineered.csv'\n",
    "\n",
    "print('library and configuration ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6616f5",
   "metadata": {},
   "source": [
    "# üóÉÔ∏è **Train and Test Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d82131a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (18942, 39)\n",
      "Test Shape  : (1077, 39)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_PATH_PROCESSED)\n",
    "test = pd.read_csv(TEST_PATH_PROCESSED)\n",
    "\n",
    "print('Train shape :', train.shape)\n",
    "print('Test Shape  :', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa5fe5",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0deea016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To preserve original dataset, we copy just to give some demonstration how these feature engineering works\n",
    "train_lore = train.copy()\n",
    "test_lore = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3dd2dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_map = {\n",
    "    'Unknown': 1, 'Opaque Ice': 2, 'Overlapping': 3,\n",
    "    'Super-Cooled Water': 4, 'Cirrus': 5, 'Fog': 6,\n",
    "    'Water': 7, 'Overshooting': 8,\n",
    "    'Probably Clear': 9, 'Clear': 10\n",
    "}\n",
    "\n",
    "train_lore['Cloud Type'] = train_lore['Cloud Type'].map(cloud_map)\n",
    "test_lore['Cloud Type'] = test_lore['Cloud Type'].map(cloud_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0dd3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after time features : (18942, 44)\n",
      "Test shape after time features  : (1077, 44)\n"
     ]
    }
   ],
   "source": [
    "def add_time_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Standardize timestamp\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "    df = df.sort_values('Timestamp')\n",
    "\n",
    "    # Shift time -5h (solar noon correction)\n",
    "    solar_time = df['Timestamp'] - pd.Timedelta(hours=5)\n",
    "    solar_hour = solar_time.dt.hour\n",
    "\n",
    "    # Cyclical hour\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * solar_hour / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * solar_hour / 24)\n",
    "\n",
    "    # Cyclical month\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['Timestamp'].dt.month / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['Timestamp'].dt.month / 12)\n",
    "\n",
    "    # Day-of-year (for astronomy)\n",
    "    df['doy'] = solar_time.dt.dayofyear\n",
    "\n",
    "    return df\n",
    "\n",
    "train_time = add_time_features(train_lore)\n",
    "test_time = add_time_features(test_lore)\n",
    "\n",
    "print('Train shape after time features :', train_time.shape)\n",
    "print('Test shape after time features  :', test_time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "173bfeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after astronomy features : (18942, 48)\n",
      "Test shape after astronomy features  : (1077, 48)\n"
     ]
    }
   ],
   "source": [
    "def add_astronomy_features(df):\n",
    "    df = df.copy()\n",
    "    doy = df['doy']\n",
    "\n",
    "    # Solar declination\n",
    "    delta = 23.45 * np.sin(np.radians(360 * (284 + doy) / 365))\n",
    "    df['solar_declination'] = delta\n",
    "\n",
    "    # Equation of Time\n",
    "    B = np.radians((doy - 81) * 360 / 365)\n",
    "    df['equation_of_time'] = (\n",
    "        9.87 * np.sin(2*B) - 7.53 * np.cos(B) - 1.5 * np.sin(B)\n",
    "    )\n",
    "\n",
    "    # Earth-Sun distance\n",
    "    df['sun_earth_distance_factor'] = 1 + 0.033 * np.cos(np.radians(360 * doy / 365))\n",
    "    df['extraterrestrial_radiation'] = 1367 * df['sun_earth_distance_factor']\n",
    "\n",
    "    return df\n",
    "\n",
    "train_astro = add_astronomy_features(train_time)\n",
    "test_astro = add_astronomy_features(test_time)\n",
    "\n",
    "print('Train shape after astronomy features :', train_astro.shape)\n",
    "print('Test shape after astronomy features  :', test_astro.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ec94969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after sun features : (18942, 49)\n",
      "Test shape after sun features  : (1077, 49)\n"
     ]
    }
   ],
   "source": [
    "def add_sun_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    sunrise_dt = pd.to_datetime(df['sunrise'])\n",
    "    sunset_dt = pd.to_datetime(df['sunset'])\n",
    "\n",
    "    # length of daylight\n",
    "    df['sunHour'] = (sunset_dt - sunrise_dt).dt.total_seconds()\n",
    "\n",
    "    # day/night flag\n",
    "    curr = df['Timestamp'].dt.time\n",
    "    rise = sunrise_dt.dt.time\n",
    "    set_  = sunset_dt.dt.time\n",
    "\n",
    "    df['is_daytime'] = [\n",
    "        1 if (r <= c <= s) else 0\n",
    "        for c, r, s in zip(curr, rise, set_)\n",
    "    ]\n",
    "\n",
    "    return df\n",
    "\n",
    "train_sun = add_sun_features(train_astro)\n",
    "test_sun = add_sun_features(test_astro)\n",
    "\n",
    "print('Train shape after sun features :', train_sun.shape)\n",
    "print('Test shape after sun features  :', test_sun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "06b02267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after physics features : (18942, 52)\n",
      "Test shape after physics features  : (1077, 52)\n"
     ]
    }
   ],
   "source": [
    "def add_physics_features(df):\n",
    "    df = df.copy()\n",
    "    eps = 1e-6\n",
    "\n",
    "    df['clearsky_index'] = df['GHI'] / (df['Clearsky GHI'] + eps)\n",
    "    df['diffuse_fraction'] = df['DHI'] / (df['GHI'] + eps)\n",
    "\n",
    "    # wind cooling using Kelvin\n",
    "    df['wind_cooling_potential'] = df['windspeedKmph'] / (df['tempC'] + 273.15)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_physics = add_physics_features(train_sun)\n",
    "test_physics = add_physics_features(test_sun)\n",
    "\n",
    "print('Train shape after physics features :', train_physics.shape)\n",
    "print('Test shape after physics features  :', test_physics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "14d9bbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after rolling features : (18942, 55)\n",
      "Test shape after rolling features  : (1077, 55)\n"
     ]
    }
   ],
   "source": [
    "def add_time_dynamic_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # lag 1h reference timestamp\n",
    "    df['target_time_1h'] = df['Timestamp'] - pd.Timedelta(hours=1)\n",
    "\n",
    "    # lookup table\n",
    "    lookup = df[['Timestamp', 'GHI', 'cloudcover']].copy()\n",
    "    lookup.columns = ['ts_ref', 'GHI_lag1', 'cloudcover_lag1']\n",
    "\n",
    "    df = df.merge(lookup, left_on='target_time_1h',\n",
    "                  right_on='ts_ref', how='left')\n",
    "\n",
    "    # rolling 3-hour mean\n",
    "    idx = df.set_index('Timestamp')\n",
    "    df['GHI_rolling_mean_3h'] = (\n",
    "        idx['GHI'].rolling('3h', min_periods=1).mean().values\n",
    "    )\n",
    "\n",
    "    # cleanup + fill\n",
    "    df.drop(columns=['target_time_1h', 'ts_ref'], inplace=True)\n",
    "    df[['GHI_lag1','cloudcover_lag1','GHI_rolling_mean_3h']] = \\\n",
    "        df[['GHI_lag1','cloudcover_lag1','GHI_rolling_mean_3h']].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_roll = add_time_dynamic_features(train_physics)\n",
    "test_roll = add_time_dynamic_features(test_physics)\n",
    "\n",
    "print('Train shape after rolling features :', train_roll.shape)\n",
    "print('Test shape after rolling features  :', test_roll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a5b6177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after gradient features : (18942, 59)\n",
      "Test shape after gradient features  : (1077, 59)\n"
     ]
    }
   ],
   "source": [
    "def add_gradient_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['GHI_diff_1h'] = df['GHI'] - df['GHI_lag1']\n",
    "    df['cloudcover_diff_1h'] = df['cloudcover'] - df['cloudcover_lag1']\n",
    "    df['clearsky_index_diff'] = df['clearsky_index'].diff().fillna(0)\n",
    "\n",
    "    # 2nd derivative (acceleration)\n",
    "    df['GHI_acceleration'] = df['GHI_diff_1h'].diff().fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_grad = add_gradient_features(train_roll)\n",
    "test_grad = add_gradient_features(test_roll)\n",
    "\n",
    "print('Train shape after gradient features :', train_grad.shape)\n",
    "print('Test shape after gradient features  :', test_grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "84bf611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after weather clustering : (18942, 60)\n",
      "Test shape after weather clustering  : (1077, 60)\n"
     ]
    }
   ],
   "source": [
    "def fit_weather_clusters(train_df, n_clusters=4):\n",
    "    features = [\n",
    "        'cloudcover_lag1',\n",
    "        'humidity',\n",
    "        'windspeedKmph',\n",
    "        'GHI_rolling_mean_3h',\n",
    "        'clearsky_index',\n",
    "        'diffuse_fraction'\n",
    "    ]\n",
    "\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    model.fit(train_df[features].fillna(0))\n",
    "\n",
    "    return model, features\n",
    "\n",
    "def apply_weather_clusters(df, model, features):\n",
    "    df = df.copy()\n",
    "    df['weather_cluster'] = model.predict(df[features].fillna(0))\n",
    "    return df\n",
    "\n",
    "\n",
    "cluster_model, cluster_feats = fit_weather_clusters(train_grad)\n",
    "\n",
    "train_cluster = apply_weather_clusters(train_grad, cluster_model, cluster_feats)\n",
    "test_cluster  = apply_weather_clusters(test_grad, cluster_model, cluster_feats)\n",
    "\n",
    "print('Train shape after weather clustering :', train_cluster.shape)\n",
    "print('Test shape after weather clustering  :', test_cluster.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6fc4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after STL features : (18942, 63)\n",
      "Test shape after STL features  : (1077, 63)\n"
     ]
    }
   ],
   "source": [
    "def fit_stl_decomposition(train_df, period=24):\n",
    "    # Fit STL on train\n",
    "    stl = STL(train_df['GHI'].fillna(0), period=period).fit()\n",
    "\n",
    "    train_trend = stl.trend\n",
    "    train_seasonal = stl.seasonal\n",
    "    train_resid = stl.resid\n",
    "\n",
    "    # Fit linear models to approximate patterns for test set\n",
    "    t = np.arange(len(train_df)).reshape(-1, 1)\n",
    "\n",
    "    trend_model = LinearRegression().fit(t, train_trend)\n",
    "    seasonal_model = LinearRegression().fit(t, train_seasonal)\n",
    "    resid_model = LinearRegression().fit(t, train_resid)\n",
    "\n",
    "    return trend_model, seasonal_model, resid_model\n",
    "\n",
    "def apply_stl_features(df, trend_model, seasonal_model, resid_model):\n",
    "    df = df.copy()\n",
    "    t = np.arange(len(df)).reshape(-1, 1)\n",
    "\n",
    "    df['GHI_trend'] = trend_model.predict(t)\n",
    "    df['GHI_seasonal'] = seasonal_model.predict(t)\n",
    "    df['GHI_residual'] = resid_model.predict(t)\n",
    "\n",
    "    return df\n",
    "\n",
    "trend_m, season_m, resid_m = fit_stl_decomposition(train_cluster)\n",
    "\n",
    "train_stl = apply_stl_features(train_cluster, trend_m, season_m, resid_m)\n",
    "test_stl  = apply_stl_features(test_cluster, trend_m, season_m, resid_m)\n",
    "\n",
    "print('Train shape after STL features :', train_stl.shape)\n",
    "print('Test shape after STL features  :', test_stl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56120c",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è **Feature Engineering Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "94487642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train engineered shape : (18942, 63)\n",
      "Test engineered shape  : (1077, 63)\n"
     ]
    }
   ],
   "source": [
    "fe = preprocessing.FeatureEngineering(n_clusters=4, stl_period=24)\n",
    "\n",
    "fe.fit(train)\n",
    "\n",
    "train_engineered = fe.transform(train)\n",
    "test_engineered  = fe.transform(test)\n",
    "\n",
    "print('Train engineered shape :', train_engineered.shape)\n",
    "print('Test engineered shape  :', test_engineered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afcd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moonrise             629\n",
       "moonset              639\n",
       "DHI                 1044\n",
       "DNI                 1044\n",
       "GHI                 1044\n",
       "Clearsky DHI        1044\n",
       "Clearsky DNI        1044\n",
       "Clearsky GHI        1044\n",
       "clearsky_index      1044\n",
       "diffuse_fraction    1044\n",
       "GHI_diff_1h         1044\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_engineered.isna().sum()[train_engineered.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7432b339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test engineered saved to ..\\data\\processed\\train_engineered.csv and ..\\data\\processed\\test_engineered.csv\n"
     ]
    }
   ],
   "source": [
    "train_engineered.to_csv(TRAIN_PATH_ENGINEERED, index=False)\n",
    "test_engineered.to_csv(TEST_PATH_ENGINEERED, index=False)\n",
    "\n",
    "print(f'Train and Test engineered saved to {TRAIN_PATH_ENGINEERED} and {TEST_PATH_ENGINEERED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb929a",
   "metadata": {},
   "source": [
    "# üì¶ **Preprocessor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1e609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a9fb94e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_feature_groups(\n",
    "#     df, target_col, cyclical_cols, manual_drop_cols=None\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Memisahkan kolom menjadi Numerical, Ordinal, dan Cyclical secara otomatis.\n",
    "#     \"\"\"\n",
    "#     if manual_drop_cols is None:\n",
    "#         manual_drop_cols = ['tempC', 'DewPointC', 'Pressure'] # Default drop\n",
    "\n",
    "#     # Kolom yang pasti dibuang (Target + Cyclical mentah + Manual Drop)\n",
    "#     features_to_drop = [target_col] + cyclical_cols + manual_drop_cols\n",
    "\n",
    "#     # Numerical: Ambil semua angka, lalu buang yang masuk daftar drop\n",
    "#     num_features = df.select_dtypes(np.number).columns.difference(features_to_drop).tolist()\n",
    "#     # Ordinal: Hardcoded sesuai strategimu\n",
    "#     ord_features = ['Cloud Type']\n",
    "#     # Cyclical: Sesuai input\n",
    "#     cyc_features = cyclical_cols\n",
    "\n",
    "#     # Gabungkan semua untuk select X nanti\n",
    "#     all_selected = list(set(num_features + ord_features + cyc_features))\n",
    "\n",
    "#     print(f\"üìä Features Summary:\")\n",
    "#     print(f\"   - Numerical : {len(num_features)}\")\n",
    "#     print(f\"   -   Ordinal : {len(ord_features)}\")\n",
    "#     print(f\"   -  Cyclical : {len(cyc_features)}\")\n",
    "#     print(f\"   -     TOTAL : {len(all_selected)}\")\n",
    "\n",
    "#     return num_features, ord_features, cyc_features, all_selected\n",
    "\n",
    "# def build_preprocessor(num_feat, ord_feat, cyc_feat):\n",
    "#     \"\"\"\n",
    "#     Menyusun ColumnTransformer agar rapi.\n",
    "#     \"\"\"\n",
    "#     # Sub-pipeline untuk Cyclical\n",
    "#     cyclical_pipeline = Pipeline([\n",
    "#         ('cyclic_encoding', SolarLunarTransformer(features=cyc_feat))\n",
    "#     ])\n",
    "\n",
    "#     # Sub-pipeline untuk Numerical\n",
    "#     numerical_pipeline = Pipeline([\n",
    "#         ('numeric_imputer', SimpleImputer(strategy='mean')),\n",
    "#         ('numeric_scaler', StandardScaler())\n",
    "#     ])\n",
    "\n",
    "#     # Main Transformer\n",
    "#     preprocessor = ColumnTransformer(transformers=[\n",
    "#         ('ord', 'passthrough', ord_feat),\n",
    "#         ('cyc', cyclical_pipeline, cyc_feat),\n",
    "#         ('num', numerical_pipeline, num_feat),\n",
    "#     ])\n",
    "\n",
    "#     return preprocessor\n",
    "\n",
    "# # Setup Data & Features\n",
    "# solar_lunar = ['moonrise', 'moonset', 'sunrise', 'sunset']\n",
    "\n",
    "# num_cols, ord_cols, cyc_cols, sel_features = get_feature_groups(\n",
    "#     train_engineered, '% Baseline', solar_lunar\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
