{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaner Utility\n",
    "import src.preprocessing as preprocessing\n",
    "\n",
    "# Reload shortcut\n",
    "def r(module=preprocessing):\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d957ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_raw.copy()\n",
    "test_df = test_raw.copy()\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Standardize timestamp\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df = df.sort_values('Timestamp')\n",
    "\n",
    "    # --- CLOUD MAPPING ---\n",
    "    cloud_map = {\n",
    "        'Unknown': 0, 'Opaque Ice': 1, 'Overlapping': 2, 'Super-Cooled Water': 3,\n",
    "        'Cirrus': 4, 'Fog': 5, 'Water': 6, 'Overshooting': 7,\n",
    "        'Probably Clear': 8, 'Clear': 9\n",
    "    }\n",
    "    df['Cloud Type'] = df['Cloud Type'].map(cloud_map).fillna(0)\n",
    "\n",
    "    # --- PHYSICS CORRECTION (CRITICAL) ---\n",
    "    # Observation: Solar peak occurs at 17:00 in raw data.\n",
    "    # Adjustment: Shift time by -5 hours to align Solar Noon with 12:00.\n",
    "    # This helps the model understand the true \"shape\" of the solar day.\n",
    "    solar_time = df['Timestamp'] - pd.Timedelta(hours=5)\n",
    "    solar_hour = solar_time.dt.hour\n",
    "    doy = solar_time.dt.dayofyear\n",
    "\n",
    "    # --- CYCLICAL FEATURES ---\n",
    "    # Calculated on Solar Time for better alignment with physics\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * solar_hour / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * solar_hour / 24)\n",
    "\n",
    "    # Monthly cycles\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['Timestamp'].dt.month / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['Timestamp'].dt.month / 12)\n",
    "\n",
    "    # --- ASTRONOMICAL FEATURES ---\n",
    "    # Solar Declination (Cooper 1969)\n",
    "    delta = 23.45 * np.sin(np.radians(360 * (284 + doy) / 365))\n",
    "    df['solar_declination'] = delta\n",
    "\n",
    "    # Equation of Time (EoT)\n",
    "    B = np.radians((doy - 81) * 360 / 365)\n",
    "    df['equation_of_time'] = 9.87 * np.sin(2*B) - 7.53 * np.cos(B) - 1.5 * np.sin(B)\n",
    "\n",
    "    # Earth-Sun Distance Factor (Eccentricity)\n",
    "    df['sun_earth_distance_factor'] = 1 + 0.033 * np.cos(np.radians(360 * doy / 365))\n",
    "    df['extraterrestrial_radiation'] = 1367 * df['sun_earth_distance_factor']\n",
    "\n",
    "    # --- SUNRISE / SUNSET LOGIC ---\n",
    "    # Parsing raw time strings\n",
    "    sunrise_dt = pd.to_datetime(df['sunrise'], format='%I:%M %p')\n",
    "    sunset_dt = pd.to_datetime(df['sunset'], format='%I:%M %p')\n",
    "\n",
    "    # Duration of daylight\n",
    "    df['sunHour'] = (sunset_dt - sunrise_dt).dt.total_seconds()\n",
    "\n",
    "    # Accurate daytime flag (comparing raw times)\n",
    "    curr_time = df['Timestamp'].dt.time\n",
    "    rise_time = sunrise_dt.dt.time\n",
    "    set_time = sunset_dt.dt.time\n",
    "\n",
    "    df['is_daytime'] = [\n",
    "        1 if (r <= c <= s) else 0\n",
    "        for c, r, s in zip(curr_time, rise_time, set_time)\n",
    "    ]\n",
    "\n",
    "    # --- SOLAR PHYSICS RATIOS ---\n",
    "    # Adding epsilon to avoid division by zero\n",
    "    epsilon = 1e-6\n",
    "    df['clearsky_index'] = df['GHI'] / (df['Clearsky GHI'] + epsilon)\n",
    "    df['diffuse_fraction'] = df['DHI'] / (df['GHI'] + epsilon)\n",
    "\n",
    "    # Wind Cooling Potential (using Kelvin)\n",
    "    df['wind_cooling_potential'] = df['windspeedKmph'] / (df['tempC'] + 273.15)\n",
    "\n",
    "    # --- TIME AWARE FEATURES (SMART MERGE) ---\n",
    "    # Create lag features correctly handling gaps/jumps in data\n",
    "    df['target_time_1h'] = df['Timestamp'] - pd.Timedelta(hours=1)\n",
    "\n",
    "    lookup = df[['Timestamp', 'GHI', 'cloudcover']].copy()\n",
    "    lookup.columns = ['ts_ref', 'GHI_lag1', 'cloudcover_lag1']\n",
    "\n",
    "    df = df.merge(lookup, left_on='target_time_1h', right_on='ts_ref', how='left')\n",
    "\n",
    "    # Rolling stats (3h window)\n",
    "    indexer = df.set_index('Timestamp')\n",
    "    df['GHI_rolling_mean_3h'] = indexer['GHI'].rolling('3h', min_periods=1).mean().values\n",
    "\n",
    "    # Cleanup\n",
    "    df.drop(columns=['target_time_1h', 'ts_ref'], inplace=True)\n",
    "\n",
    "    features_to_fill = ['GHI_lag1', 'cloudcover_lag1', 'GHI_rolling_mean_3h']\n",
    "    df[features_to_fill] = df[features_to_fill].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply to datasets\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb94e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_groups(\n",
    "    df, target_col, cyclical_cols, manual_drop_cols=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Memisahkan kolom menjadi Numerical, Ordinal, dan Cyclical secara otomatis.\n",
    "    \"\"\"\n",
    "    if manual_drop_cols is None:\n",
    "        manual_drop_cols = ['tempC', 'DewPointC', 'Pressure'] # Default drop\n",
    "\n",
    "    # Kolom yang pasti dibuang (Target + Cyclical mentah + Manual Drop)\n",
    "    features_to_drop = [target_col] + cyclical_cols + manual_drop_cols\n",
    "\n",
    "    # Numerical: Ambil semua angka, lalu buang yang masuk daftar drop\n",
    "    num_features = df.select_dtypes(np.number).columns.difference(features_to_drop).tolist()\n",
    "    # Ordinal: Hardcoded sesuai strategimu\n",
    "    ord_features = ['Cloud Type']\n",
    "    # Cyclical: Sesuai input\n",
    "    cyc_features = cyclical_cols\n",
    "\n",
    "    # Gabungkan semua untuk select X nanti\n",
    "    all_selected = list(set(num_features + ord_features + cyc_features))\n",
    "\n",
    "    print(f\"ðŸ“Š Features Summary:\")\n",
    "    print(f\"   - Numerical : {len(num_features)}\")\n",
    "    print(f\"   -   Ordinal : {len(ord_features)}\")\n",
    "    print(f\"   -  Cyclical : {len(cyc_features)}\")\n",
    "    print(f\"   -     TOTAL : {len(all_selected)}\")\n",
    "\n",
    "    return num_features, ord_features, cyc_features, all_selected\n",
    "\n",
    "def build_preprocessor(num_feat, ord_feat, cyc_feat):\n",
    "    \"\"\"\n",
    "    Menyusun ColumnTransformer agar rapi.\n",
    "    \"\"\"\n",
    "    # Sub-pipeline untuk Cyclical\n",
    "    cyclical_pipeline = Pipeline([\n",
    "        ('cyclic_encoding', SolarLunarTransformer(features=cyc_feat))\n",
    "    ])\n",
    "\n",
    "    # Sub-pipeline untuk Numerical\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('numeric_imputer', SimpleImputer(strategy='mean')),\n",
    "        ('numeric_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Main Transformer\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('ord', 'passthrough', ord_feat),\n",
    "        ('cyc', cyclical_pipeline, cyc_feat),\n",
    "        ('num', numerical_pipeline, num_feat),\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3dec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING\n",
    "# optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "# def objective(trial):\n",
    "#     param_grid = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 1000, 3000, step=100),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 5, 12),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True), # L1 Regularization\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True), # L2 Regularization\n",
    "\n",
    "#         'tree_method': 'hist',\n",
    "#         'random_state': SEED,\n",
    "#         'n_jobs': -1,\n",
    "#         'device': 'cuda'\n",
    "#     }\n",
    "\n",
    "#     # Buat Model dengan parameter dari trial\n",
    "#     model = XGBRegressor(**param_grid)\n",
    "\n",
    "#     # Masukkan ke Pipeline\n",
    "#     pipeline_optuna = Pipeline(steps=[\n",
    "#         ('preprocessor', preprocessor),\n",
    "#         ('model', model)\n",
    "#     ])\n",
    "\n",
    "#     # Cross Validation\n",
    "#     cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "#     scores = cross_val_score(pipeline_optuna, X, y, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=1)\n",
    "\n",
    "#     rmse = np.sqrt(-scores.mean())\n",
    "#     return -scores.mean()\n",
    "\n",
    "# study = optuna.create_study(direction='minimize') # Minimize error\n",
    "# study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# print('Best hyperparameters:', study.best_params)\n",
    "# print('Best RMSE:', study.best_value)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
